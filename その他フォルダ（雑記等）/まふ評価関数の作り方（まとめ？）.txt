学習用の定跡は作ってみたいと思いますが評価関数作成は本業？ではないので、適当にやったことを書いておきます。


①やねepoch0からスタート


②やね氏ブログ「教師局面生成時のランダムムーブについて」書込み引用
＞評価関数を作ってみた感想ですが、
やね式学習部のアルゴリズムが強力だなと。
教師局面の性質をモロに反映するので定跡で方向性を変えれます。

今やっているのは「まふ定跡」ver1からver11までを学習させています。
元々、前verの悪い所を直しながら作っているので、それを追体験させている感じです。
そのままだとさすがに局面が狭いので、７六歩２５％、２六歩２５％、中飛車１０％、四間飛車１０％、その他３０％くらいに定跡を７０手まで使用で任意に散らしています。
※定跡が多く当たったと思われる生成時と、ほとんど当たらなかったと思われる生成時間の差は最大で３割程度です。

あとは「雑巾絞り」は複数回絞るのが普通だと思うので、爺さん世代の教師局面も学習に使っています。
例）ver3で生成したdepth３の１億局面をver5で生成したdepth３の１億局面のときも使って学習しています。（競走馬のインブリード的な発想とdepth３で生成される教師局面に棋力の差はあまり無いだろうと）

uuunuuun氏のブログとの比較ですが、同じdepth３でもレート向上が大きいと思います。
とりあえず頭打ちになったと思ったら結果を報告します。

●要はdepth３×１億局面生成を１１回実施（私の税込み６９００円のＰＣで４億局面／日）
途中レート計測はせずに５回連続とかでやって、４回目と５回目を比較して５回目が強かったらそのまま続行とかで時間削減


③やね氏ブログ「『Shivoray』(全自動雑巾絞り機)公開しました」書込み引用
＞途中経過となりますが「教師局面生成時のランダムムーブについて」のコメントのようにver11まで終わって、
Depth３＝１億局面（一部再利用）×１１回elmo絞り
定跡込みでelmoにいくらか勝ちますね。

実質Depth３＝１１億局面しか学習していないので、４コア８スレッドのＰＣだと２日でWCSC27３位くらいのレートまでいけるみたいですね。

ここからはDepth６でやってみますが、私のＰＣだと１億局面生成に３日かかるようなので報告は遅くなるかと。

とりあえず今言えるのは、やね学習部はチートツール並みの威力があるので、Depth３とかで上手い使い方を練習してからDepth６で始めても遅く無いだろうと


④上記によりＲ３８００相当になったので、そこからDepth６×３億局面生成

●公開はしませんが、定跡使用による高速教師局面生成を発見。
１億局面／３日が２．４億局面／３日になる


⑤やね氏ブログ「評価関数のキメラ化コマンド公開しました」書込み引用
＞３億局面でelmoと互角になった手法「無限絞り」を報告します。

４つの定跡を用いてランダムムーブ無しの教師局面を生成しました。
①最も勝率の高い定跡局面２５％
②広い局面の定跡局面２５％
③相掛かり定跡局面２５％
④横歩取り定跡局面１５％
残りの１０％は各定跡のConsiderBookMoveCountを切って、類似局面の採用率の低い将棋ソフトが間違いやすい局面を任意で生成。

これらをシャッフル後にepoch0で学習すると、シャッフルによってエントロピーロスが結構違うことを発見。
ロスが大きい評価関数と小さい評価関数のどっちが強いか実験中に「同じ教師局面なのにこれだけ性質が違うなら何回も使える？」
１回目絞る→強くなった評価関数→同じ教師局面シャッフル→２回目絞る→強くなった評価関数→同じ教師局面シャッフル→３回目絞る→強くなった評価関数→同じ教師局面シャッフル→４回目絞る→満足行くまでループ。

とりあえず一番時間がかかっていた教師局面生成部の計算リソースの大幅な削減が出来るのではないでしょうか？
おそらく大別する４種類の違う性質を持つ教師局面の勝ちと負けの８種類の組み合わせを、シャッフルの偶然的確率で様々な訓練データ（ミニバッチ）に変質出来たことで同じ教師局面が再利用が出来たのだと思います。

私は定跡を駆使しましたが、性質の違う教師局面を用意出来れば多少なり効果が見込めると思うので、
rezero＝１億局面
tanuki-wcsc27＝１億局面
Qhapaq-wcsc27＝１億局面
Yomita-wcsc27＝１億局面
こんな組み合わせでも出来るのではないでしょうか？

さらにrezero＋tanuki-＋Qhapaq＋Yomitaをキメラしたものから絞れば効率的では？

やね氏が寝る前にボタン１つでループ学習してくれる全自動学習機を作成してくれるでしょう。
※なんとなくですが、シャッフルした教師局面をさらにシャッフルすると混ざりが良くなりすぎる気がしたので、最初に生成した教師局面を毎回シャッフル使用しました
※lambdaもいろいろ変えてみましたが、0.33が安定していました（変えるとあきらかに弱くなったこともあるので、逆に良くなることもあるかも）
※batchsizeはいろいろ変えました
※私は出来ませんが、最後は出来た評価関数から多くの教師局面でその評価関数の高い勝率に固めて仕上げすることが望ましいと思います。

●このときのDepth６×３億局面をepoch0に１回「elmo絞り」適用でelmoに１０％勝てたので、ゼロから１発でＲ３６００
これを「無限絞り」するとＲ４０００相当になった。


⑥やね氏ブログ「評価関数のキメラ化コマンド公開しました」書込み引用
＞uuunuuun氏にレート計測を依頼してみました。

私がelmoと対局させた棋譜を見た感想ですが、、
①駒割がすごくおかしくて、駒交換が起きる局面だとかなり不利
②定跡学習したからか、定跡抜けるとelmoと常に評価値３００くらいの差がある（自分が良いと言っている。勝敗ボーナスが大きく付いた？）
③桂馬をあまり使わない（歩に余裕があると歩を打って３筋と７筋を閉じてしまう。相掛かり比率が高かったので角道を閉じた局面を学習しすぎた？）
④elmoに反省させられると逆転出来ない（教師局面数が少ないからかelmo比で粘りが無い。自分が不利になるとすぐあきらめる子供のようだ）
⑤終盤力が低い（教師局面数が少ないからか、とんでもない読み抜けをすることがある）

いろいろ問題山積みな評価関数ですが、自己対局ではelmoに半分くらい勝ってます。
単純にまだ先がある感じです。

●uuunuuun氏にレート計測結果。Twitter引用
＞まふさん育成の評価関数＋定跡
対elmo (定跡入り) 48-2-50(ツィート済み)
対eloqhappa(定跡切) 34-1-34
対リゼロ8(定跡切) 33-4-27
対局数稼げませんでしたが、無限絞りうまく行っているようです。
4:16 - 2017年7月1日 

●棋譜の一部はこのGitに貼っています（全部出せないのは第５回電王戦後に配布する戦型別定跡を使っているので）


⑦上記の問題点を解消したものが現在の最新verです。


⑧私の開発環境ではこれ以上無理なので、私の１０倍程度の開発環境をお持ちの方に開発継続を引き継いで頂きました。
