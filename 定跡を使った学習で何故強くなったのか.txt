私が採用した定跡学習はＳＧＤ（確率的勾配降下法）において分類するのなら「カリキュラム学習」に分類されると思います。

ちゃんとした論文も存在するのですが、私は英語も読めませんし翻訳された内容を見ると、
「カリキュラム学習」とは訓練データをあえてシャッフルせずに意味のある順番に提供し、より良く収束出来るかもしれない手法のようです。

しかし「将棋を上手く学習出来るカリキュラムって何よ？」って言われると「そんなん知らんがな」となっちゃう机上の空論扱いになりやすい手法のようです。
ですから通常は訓練データをシャッフルして偏りを減らすことで、上手く収束させる学習方法が主流とのこと。
でも結局同じ条件のelmo絞り一辺倒だと問題が難しくなると何処かで行き詰まるそうです。（elmoの限界点付近）
そうなるとdepthを上げたり、さらなるビッグデータ（計算リソース）が必要となる悪循環？に陥るそうです。

「elmo絞り」とはビッグデータから偶然に意味のある順番に並んだ評価パラメタを「勝敗項」により意味ある順で学習結果が収束するようにしている手法と言えます。


上記より私が考えたのは、全部やれば良いじゃない？でした。

シャッフルもして訓練データの偏りを減らしながら、定跡を使ったカリキュラムを与え、bookmovesの変化で意味のある順番に並んだ評価パラメタを「勝敗項」により学習させるです。

しかし、評価関数を作成し始めたときは「定跡を使ったカリキュラム学習」に効果があるのか半信半疑でしたが、
「局面の３駒関係」開発者様が私の評価関数を可視化登録して頂きましたことで確信を得ることが出来ました。
（自分が創作した定跡がどのくらい学習出来ているのかが色味で見ることが出来たから）

こういったよくばりな発想で学習してみた結果が「学習用定跡作成プロジェクト」です。

このように意味の分からない「黒魔術」的な論法を使用したものではなく、ちゃんと論文も存在するＳＧＤの手法を将棋ソフトの学習に適用した形なので、開発者の方も再現しさらに発展させてほしいと思います。